{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f8605-ca6b-4ef0-a698-b43159bfedeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66541bc4-7386-4abb-8331-7b8e213cbf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "class NotApproved(Exception):\n",
    "    \"\"\"Custom exception.\"\"\"\n",
    "\n",
    "\n",
    "def human_approval(msg: AIMessage) -> AIMessage:\n",
    "    \"\"\"Responsible for passing through its input or raising an exception.\n",
    "\n",
    "    Args:\n",
    "        msg: output from the chat model\n",
    "\n",
    "    Returns:\n",
    "        msg: original output from the msg\n",
    "    \"\"\"\n",
    "    tool_strs = \"\\n\\n\".join(\n",
    "        json.dumps(tool_call, indent=2) for tool_call in msg.tool_calls\n",
    "    )\n",
    "    input_msg = (\n",
    "        f\"Do you approve of the following tool invocations\\n\\n{tool_strs}\\n\\n\"\n",
    "        \"Anything except 'y'/'yes' (case-insensitive) will be treated as a no.\\n >>>\"\n",
    "    )\n",
    "    resp = input(input_msg)\n",
    "    if resp.lower() not in (\"yes\", \"y\"):\n",
    "        raise NotApproved(f\"Tool invocations not approved:\\n\\n{tool_strs}\")\n",
    "    return msg\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version = os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    api_key = os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'),\n",
    ")\n",
    "\n",
    "@tool\n",
    "def count_emails(last_n_days: int) -> int:\n",
    "    \"\"\"Dummy function to count number of e-mails. Returns 2 * last_n_days.\"\"\"\n",
    "    return last_n_days * 2\n",
    "\n",
    "\n",
    "@tool\n",
    "def send_email(message: str, recipient: str) -> str:\n",
    "    \"\"\"Dummy function for sending an e-mail.\"\"\"\n",
    "    return f\"Successfully sent email to {recipient}.\"\n",
    "\n",
    "\n",
    "tools = [count_emails, send_email]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def call_tools(msg: AIMessage) -> List[Dict]:\n",
    "    print(msg)\n",
    "    \"\"\"Simple sequential tool calling helper.\"\"\"\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    tool_calls = msg.tool_calls.copy()\n",
    "    for tool_call in tool_calls:\n",
    "        tool_call[\"output\"] = tool_map[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        print(tool_call['args'])\n",
    "    return tool_calls\n",
    "\n",
    "\n",
    "chain = llm_with_tools | human_approval | call_tools\n",
    "chain.invoke(\"how many emails did i get in the last 5 days?\")\n",
    "chain.invoke(\"how many emails did i get in the last 5 days?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7941f64-5149-4c7c-9fa2-57ee00404eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77d845-9138-4165-b6c5-59776519bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb790f83-f753-4854-b686-2974dae456c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907330b-1495-4b07-b151-b02b4c309288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def check_weather(location: str) -> str:\n",
    "    '''Return the weather forecast for the specified location.'''\n",
    "    return f\"It's always sunny in {location}\"\n",
    "\n",
    "graph = create_react_agent(\n",
    "    \"anthropic:claude-3-7-sonnet-latest\",\n",
    "    tools=[check_weather],\n",
    "    prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    "for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236142d-b04d-440a-8827-1982d6d6f378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
