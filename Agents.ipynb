{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a97010-5970-487f-9bd7-3c83ee5ec800",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196ef16-d269-4311-b196-aa4d9e742408",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a78d8-7bea-43af-b534-e12b5ab5c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import bs4\n",
    "from typing import Annotated, Sequence, List\n",
    "from typing_extensions import TypedDict\n",
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG \n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# SQL DB\n",
    "import sqlite3\n",
    "import requests\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import AgentExecutor, create_sql_agent\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import StaticPool\n",
    "\n",
    "# Tools\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Langgraph\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10fa3c-a83d-403e-b96c-6bfd54b34666",
   "metadata": {},
   "source": [
    "## Instantiate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dfdee-c104-4bfb-8a52-116c98ab85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version = os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    api_key = os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    ")\n",
    "# llm.invoke('Hey')\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment = os.getenv('AZURE_OPENAI_EMBEDDING'),\n",
    "    api_version = os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    api_key = os.getenv('AZURE_OPENAI_EMBEDDING_API_KEY')\n",
    ")\n",
    "# embeddings.embed_query('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3a115-3fa1-41b3-b206-d3dea243b2a1",
   "metadata": {},
   "source": [
    "## Create Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bde1c5-e910-4f3f-b790-ee78a20b0ab4",
   "metadata": {},
   "source": [
    "### Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c5f23-06fb-4dcf-8f5e-42445b657b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    decision: str\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498631ac-6917-4335-84fc-591b28248f56",
   "metadata": {},
   "source": [
    "### RAG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78987e4-f1af-4a6d-9849-abfd082c0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# Load amd chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=('post-content', 'post-title','post-header')\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Docs\n",
    "docs = loader.load()\n",
    "\n",
    "# Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index Chunk\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41451cb-695e-431b-987a-d8ed05fdde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A\n",
    "\n",
    "def format_docs(docs: List[Document]):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def rag_agent(state: AgentState):\n",
    "    global llm\n",
    "    rag_agent_llm = llm\n",
    "\n",
    "    retriever = vector_store.as_retriever()\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
    "        If you do not' know the answer, just say that you don't know. Use three sentences maximum and keep the answer consice.\n",
    "        Question:{question}\n",
    "        Context:{context}\n",
    "        Answer:\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate([\n",
    "        ('system', system_prompt + \"Context: {context}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | rag_agent_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # chain_multimodal_rag = (\n",
    "    #    {\n",
    "    #      'context': retriever | RunnableLambda(ingestion.get_image_description)\n",
    "    #      'question': RunnablePassthrough()\n",
    "    #    }\n",
    "    #    | RunnableLambdba(ingestion.mutlimodel_prompt)\n",
    "    #    | llm\n",
    "    #    | StrOutputParser() \n",
    "    #response = rag_chain.invoke({'question': state['input']})\n",
    "    response = rag_chain.invoke(state['input'])\n",
    "    return {'output': response, 'input': state['input']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677114d2-7849-4598-af62-e21300f1c6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c270bc9-71ab-48fe-a126-34c59859b55a",
   "metadata": {},
   "source": [
    "### SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfff455-aa7a-4ea0-a946-d1ad32d99821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL database\n",
    "\n",
    "def get_engine_for_chinook_db():\n",
    "    \"\"\"Pull sql file, populate in-memory database, and create engine.\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
    "    response = requests.get(url)\n",
    "    sql_script = response.text\n",
    "\n",
    "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "    connection.executescript(sql_script)\n",
    "    return create_engine(\n",
    "        \"sqlite://\",\n",
    "        creator=lambda: connection,\n",
    "        poolclass=StaticPool,\n",
    "        connect_args={\"check_same_thread\": False},\n",
    "    )\n",
    "\n",
    "\n",
    "engine = get_engine_for_chinook_db()\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "sql_toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "# sql_toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f358e-78d5-4a4b-aa8b-8f4ea1f2d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question =  \"Which country's customers spent the most?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0439806-b68a-45b5-bde7-00e557961503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm=llm, tools=sql_toolkit.get_tools(), prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=sql_toolkit.get_tools())\n",
    "\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6eec3-8490-437e-b163-22d24f78c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B\n",
    "system_prompt_sql = \"\"\"\n",
    "    You are a helpful AI assistant expert in querying SQL Database to find answers to user's question about customers. If you can't find the answer, say ' I am unable to find the answer.'\n",
    "\"\"\"\n",
    "sql_agent = create_sql_agent(\n",
    "    llm=llm,\n",
    "    agent_type='openai-tools',\n",
    "    toolkit=sql_toolkit,\n",
    "    agent_exectutor_kwargs=dict(handle_parsing_errors=True)\n",
    ")\n",
    "prompt_sql = ChatPromptTemplate([\n",
    "    (\"system\", system_prompt_sql),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "sql_agent.invoke(prompt_sql.format(question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16294aaa-47c0-48e7-83ab-80ca68c9cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_agent(state):\n",
    "    global llm\n",
    "    sql_llm = llm\n",
    "\n",
    "    engine = get_engine_for_chinook_db()\n",
    "\n",
    "    db = SQLDatabase(engine)\n",
    "    sql_toolkit = SQLDatabaseToolkit(db=db, llm=sql_llm)\n",
    "\n",
    "    sql_agent = create_sql_agent(\n",
    "        llm=llm,\n",
    "        agent_type='openai-tools',\n",
    "        toolkit=sql_toolkit,\n",
    "        agent_exectutor_kwargs=dict(handle_parsing_errors=True)\n",
    "    )\n",
    "    prompt_sql = ChatPromptTemplate([\n",
    "        (\"system\", system_prompt_sql),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    response = sql_agent.invoke(prompt_sql.format(question=state['input']))\n",
    "\n",
    "    return {'output': response['output'], 'input': state['input']}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe2ba4-c498-4198-b6c7-9e1202878b75",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76f299-f991-4352-8c8a-34b28904fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "@tool\n",
    "def buy():\n",
    "    \"\"\"Buys stuff\"\"\"\n",
    "    return f'Bought stuff'\n",
    "\n",
    "@tool\n",
    "def sell():\n",
    "    \"\"\"Sells stuff\"\"\"\n",
    "    return f'Sold 10 apples stuff'\n",
    "\n",
    "# Tool agent\n",
    "def tool_agent(state: AgentState):\n",
    "    global llm\n",
    "    tool_llm = llm\n",
    "\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"You are an agent that ... \"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\")\n",
    "    ])\n",
    "\n",
    "    tools = [buy, sell]\n",
    "    tool_agent = create_openai_tools_agent(\n",
    "        tools=tools,\n",
    "        llm=tool_llm,\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    agent_executor = AgentExecutor(agent=tool_agent, tools=tools)\n",
    "\n",
    "    response = agent_executor.invoke({'input': state['input']})\n",
    "\n",
    "    return {'output':response, 'input': state['input']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9f923-1aae-4336-be1c-e59245fe0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = os.environ.get(\"GOOGLE_CSE_ID\") \n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "# Initialize Google Search tool\n",
    "search = GoogleSearchAPIWrapper()\n",
    "search_tool = Tool(\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=search.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740b973-ac7f-40d9-ab4e-a3c627d179a0",
   "metadata": {},
   "source": [
    "### Rool Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82262c-7fe6-49d0-b3a7-04c10e5a5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "def route_tools(state: AgentState) -> Literal['rag','tool','sql',END]:\n",
    "    if state['decision']=='rag':\n",
    "        return \"rag\"\n",
    "        \n",
    "    if state['decision']=='tool':\n",
    "        return \"tool\"\n",
    "\n",
    "    if state['decision']=='sql':\n",
    "        return 'sql'\n",
    "        \n",
    "    #last_message = state[\"messages\"][-1]\n",
    "\n",
    "    #if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "    #    tool_name = last_message.tool_calls[0][\"name\"]\n",
    "    #    return tool_name\n",
    "        \n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a28ec-a867-4932-8192-c22ac0316253",
   "metadata": {},
   "source": [
    "### Chat-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712f691-c1cd-4583-9fb2-5b809a718ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_agent(state):\n",
    "    global llm\n",
    "    chat_llm = llm\n",
    "\n",
    "    prompt = ChatPromptTemplate([\n",
    "        ('system','You are agent who decised whether use rag, tool (for transaction, sell or buy) or sql agent. Only answer with rag, sql, or tool words'),\n",
    "        ('human', '{input}')\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | chat_llm\n",
    "\n",
    "    response = chain.invoke({'input': state['input']})\n",
    "\n",
    "    decision = response.content.strip().lower()\n",
    "\n",
    "    return {'decision':decision}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385962e0-9c4a-4575-98fe-a6105736c96b",
   "metadata": {},
   "source": [
    "## Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82752e97-6e30-48b7-bb36-c628f5b32aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.add_node('chat_agent', chat_agent)\n",
    "    workflow.add_node('rag_agent', rag_agent)\n",
    "    workflow.add_node('tool_agent', tool_agent)\n",
    "    workflow.add_node('sql_agent', sql_agent)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"chat_agent\",\n",
    "        route_tools,\n",
    "         {\n",
    "            \"rag\": \"rag_agent\",\n",
    "            \"tool\": \"tool_agent\",\n",
    "            \"sql\": \"sql_agent\",\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.set_entry_point('chat_agent')\n",
    "    workflow.add_edge('rag_agent',END)\n",
    "    workflow.add_edge('tool_agent',END)\n",
    "    workflow.add_edge('sql_agent',END)\n",
    "\n",
    "    workflow = workflow.compile()\n",
    "\n",
    "    return workflow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959f407-decb-4124-a170-d1b2ddce7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, Markdown, HTML\n",
    "graph = create_graph()\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb811ec-c22d-4756-a490-f5d675b5f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid  \n",
    "thread_config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}} \n",
    "for event in graph.stream({'input': 'Tell me about agentic AI'}, config=thread_config, stream_mode=['updates']):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af616cf3-7299-434f-9f1f-9931c1ebd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid  \n",
    "thread_config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}} \n",
    "for event in graph.stream({'input': \"Which country's customers spent the most?\"}, config=thread_config, stream_mode=['updates']):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea4dc2-1344-43e6-a70c-858f7375ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid  \n",
    "thread_config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}} \n",
    "for event in graph.stream({'input': \"Sell everything\"}, config=thread_config, stream_mode=['updates']):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fec1e9-f448-464a-a98f-1f113c4e1118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92469921-6987-45cd-9d18-6e69031ace33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
